from datasets.rail_defect import RDDataset
from datasets.bound1 import RDDatasetwithbound, RDDatasetwithboundval
from torch.utils.data import DataLoader
from torch import optim
import os
import time
import torch
from ptflops import get_model_complexity_info
from datetime import datetime
from torch.autograd import Variable
from utils.log import get_logger
from loss.pytorch_iou import IOU
from loss.bce_loss import BCELOSS
from loss.contrastive_loss import *
from loss.losses import *


def print_network_infor(model):
    # 输入不用指定batchsize,默认是1
    flops, params = get_model_complexity_info(model, (3, 320, 320), (1, 320, 320), as_strings=True, print_per_layer_stat=False)
    print('flops - : ', flops)
    print('params - : ', params)
    pytorch_total_params = sum(p.numel() for p in model.parameters())
    trainable_pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print('Total - :', pytorch_total_params/1000000)
    print('Trainable - :', trainable_pytorch_total_params/1000000)
    return flops, params, pytorch_total_params, trainable_pytorch_total_params


def TaskLoss(x, y):
        z = bce(x, y) + iou(x, y)
        return z


def CountTotalLoss(out, label):
    loss = 0
    out = list(out)
    for x in out:
        Lossvalue = TaskLoss(torch.sigmoid(x), label)
        loss = loss + Lossvalue
    return loss

def dice_loss(pred, mask):
    mask = F.sigmoid(mask)
    pred = F.sigmoid(pred)
    intersection = (pred * mask).sum(axis=(2, 3))
    unior = (pred + mask).sum(axis=(2, 3))
    dice = (2 * intersection + 1) / (unior + 1)
    dice = torch.mean(1 - dice)
    return dice
# class contrastive4edge(nn.Module):
#     def __init__(self, indim):
#         super(contrastive4edge, self).__init__()
#         self.conv = nn.Conv2d(1, indim, 1)
#
#     def forward(self, input, label):
#         label_ = self.conv(label)
#         label__= F.interpolate(label_, input.size()[2:], mode='bilinear', align_corners=True)
#         loss = conloss(input, label__)
#         # input = torch.sigmoid(input)
#         # loss = bce(input, label__)
#         return loss

# =============== panel ================================
# ---------------------选用GPU-----------------------------
os.environ["CUDA_VISIBLE_DEVICES"] = '0'  # TODO

if torch.cuda.is_available():
    device = torch.device('cuda')
    print('using cuda:', torch.cuda.get_device_name(0))
else:
    device = torch.device('cpu')
    print('using CPU')
print('Device:', device)
# ---------------------------------------------------------
# 从文件导入model todo
from model.d3_1 import *
# from model.new import *
# 一次读取几张图片
batchsize = 4
# 学习率
lr_rate = 1e-4
# 迭代次数
epochs = 100
rootpath = '/home/wjy/rail_362/Dataset/'
net = ANet([64, 128, 256, 512], 'shunted_b')
# net = ANet([64, 128, 320, 512], 'uniformer')
# net = ANet([64, 128, 320, 512], 'segformer_b3')
# net.load_pre('/home/wjy/RAIL_DEFECT_DETECTION/backbone/Uniformer/mask_rcnn_1x_hybrid_base.pth')
# net.load_pre('/home/wjy/RAIL_DEFECT_DETECTION/backbone/mobilevit/xxsmodel_best.pth.tar')
# net.load_pre('/home/wjy/RAIL_DEFECT_DETECTION/backbone/mobilevit/model_best.pth.tar')
# net.load_pre('/home/wjy/RAIL_DEFECT_DETECTION/backbone/segformer/mit_b3.pth')
# net.load_pre('/home/wjy/RAIL_DEFECT_DETECTION/backbone/segformer/segformer.b3.512x512.ade.160k.pth')
net = net.cuda()
modelname = time.strftime("%Y_%m_%d_%H_%M") + 'WOSCFA'  # TODO
# ========================================================

# ---------------输出信息-------------------------------
f, p, t, r = print_network_infor(net)
bestpath = './Pth/' + modelname + '_best.pth'
lastpath = './Pth/' + modelname + '_last.pth'
logdir = f'run/{time.strftime("%Y-%m-%d-%H-%M")}({modelname})'
if not os.path.exists(logdir):
    os.makedirs(logdir)
logger = get_logger(logdir)
# +++++++++++++++++++++++++++++++++++++++++
logger.info(f'Conf | use logdir {logdir}')
logger.info(f'|flops:{f}|params:{p}|total_parameter:{t/1000000}|trainable_parameters:{r/1000000}')
# +++++++++++++++++++++++++++++++++++++++++
# ---------- 加载数据集 ---------------------------------
# TrainDatasets = RDDataset(rootpath, 'train')
# ValDatasets = RDDataset(rootpath, 'val')
TrainDatasets = RDDatasetwithbound(rootpath, 'train')
ValDatasets = RDDatasetwithboundval(rootpath, 'val')
train_dataloader = DataLoader(TrainDatasets, batch_size=batchsize, shuffle=True, num_workers=4)
val_dataloader = DataLoader(ValDatasets, batch_size=batchsize, shuffle=True, num_workers=4)
# ----------------定义损失计算和优化器---------------------
bce = BCELOSS().cuda()
iou = IOU(size_average=True).cuda()
conloss = ConLoss().cuda()
conedloss = SupConLoss().cuda()
optimizer = optim.Adam(net.parameters(), lr=lr_rate, weight_decay=1e-3)
# ----------------初始变量定义------------------------------
# 用于存下最好的结果
best = [10]  # 小于10就记录
mae_sum = 0
best_mae = 1
best_epoch = 1
# =======================================================================
logger.info(f'Epochs:{epochs}  Batchsize:{batchsize}')

for epoch in range(epochs):

    if (epoch+1) % 20 == 0 and epoch != 0:
        for group in optimizer.param_groups:
            group['lr'] = 0.5 * group['lr']
            print(group['lr'])
            lr_rate = group['lr']

    # ---------------------- train --------------------------------
    net = net.train()
    train_loss = 0
    tmae = 0
    prec_time = datetime.now()
    for i, sample in enumerate(train_dataloader):

        image = Variable(sample['RGB'].cuda())
        depth = Variable(sample['depth'].cuda())
        label = Variable(sample['label'].float().cuda())
        gt_b = Variable(sample['boundary'].float().cuda())

        optimizer.zero_grad()
        # ************************************
        # TODO 根据网络修改输入输出
        out = net(image, depth)
        outa = torch.sigmoid(out['supout'][0])
        tloss = TaskLoss(outa, label)

        suploss = CountTotalLoss(out['supout'], label)
        edgeloss = bce(torch.sigmoid(out['edout'][1]), gt_b) + dice_loss(torch.sigmoid(out['edout'][1]), gt_b)
        contra_for_edge = conedloss(out['edout'][1], gt_b)
        # edgeloss = bce(torch.sigmoid(out['edgeout']), gt_b) + dice_loss(torch.sigmoid(out['edgeout']), gt_b)
        # contra_for_edge = conedloss(out['edgeout'], gt_b)
        loss_total = suploss + 0.7 * edgeloss + 0.3 * contra_for_edge
        # loss_total = suploss + 0.7 * edgeloss
        maetrain = torch.sum(torch.abs(label - outa)) / (320.0 * 320.0) #
        time = datetime.now()
        if i % 10 == 0:
            print('{}  epoch:{}/{}  {}/{}  total_loss:{} loss:{} edgeloss:{}'
                  '  '.format(time, epoch+1, epochs, i, len(train_dataloader), loss_total.item(), tloss, edgeloss))
        # ************************************
        loss_total.backward()
        optimizer.step()
        # train_loss = loss_total.item() + train_loss
        train_loss = tloss.item() + train_loss
        tmae = maetrain.item() + tmae #
    # ---------------------- val ----------------------------------
    net = net.eval()
    eval_loss = 0
    mae = 0
    with torch.no_grad():
        for j, sample in enumerate(val_dataloader):
            imageVal = Variable(sample['RGB'].cuda())
            depthVal = Variable(sample['depth'].cuda())
            labelVal = Variable(sample['label'].float().cuda())
            # **********************************************
            # TODO 根据网络修改输入输出
            out = net(imageVal, depthVal)
            outa = torch.sigmoid(out['supout'][0])
            # **********************************************
            # loss = bce(outa, labelVal)
            vloss = TaskLoss(outa, labelVal) #
            maeval = torch.sum(torch.abs(labelVal - outa)) / (320.0*320.0)
            # print('=============', j, '===============', vloss.item())
            eval_loss = vloss.item() + eval_loss #
            mae = mae + maeval.item()
    # ---------------------------------------------------------------
    cur_time = datetime.now()
    h, remainder = divmod((cur_time - prec_time).seconds, 3600)
    m, s = divmod(remainder, 60)
    time_str = '{:.0f}:{:.0f}:{:.0f}'.format(h, m, s)
    logger.info(
        f'Epoch:{epoch+1:3d}/{epochs:3d} || trainloss:{train_loss / 1500:.8f} valloss:{eval_loss / 362:.8f} || '
        f'trainmae:{tmae / 362:.8f}||valmae:{mae / 362:.8f} || lr_rate:{lr_rate} || spend_time:{time_str}')

    if (mae / 362) <= min(best):
        best.append(mae / 362)
        nummae = epoch + 1
        torch.save(net.state_dict(), bestpath)

    torch.save(net.state_dict(), lastpath)
    print('#########best mae epoch:{},best mae:{}###########'.format(nummae, min(best)))
    logger.info(f'#########best mae epoch:{nummae:3d}  || best mae:{min(best)}#########')
# ==========================================================================================

